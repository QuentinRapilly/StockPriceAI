{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stock_price_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYDl7Exa2OXq",
        "outputId": "6736ce58-aba4-4394-e750-07bdb2ac00ce"
      },
      "source": [
        "!pip install yfinance"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.67)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.6.4)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOYOZKc82X8V"
      },
      "source": [
        "## Stock DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PW3FBdA2XJn"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from typing import Union\n",
        "import torch\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3hNzf_62Yh9",
        "outputId": "f2c1b9a3-f56d-40f1-f618-c81b0dceb20b"
      },
      "source": [
        "class StockPriceDataset(Dataset):\n",
        "    def __init__(self, start_date: str=\"jj-mm-aaaa\", end_date: str=\"jj-mm-aaaa\", \n",
        "                 interval: int=1, nb_samples: int=20, transform=None,\n",
        "                 file_dir: str=\"data/\", csv_file: str=None):\n",
        "\n",
        "        # If a local data file must be loaded:\n",
        "        if csv_file is not None:\n",
        "            self.root_dir = file_dir\n",
        "            self.filename = csv_file\n",
        "            with open(os.path.join(file_dir,csv_file), 'r') as file:\n",
        "                data = pd.read_csv(file, sep=',', header='infer')\n",
        "\n",
        "        else: # Data must be loaded on an online database:\n",
        "            dataset = yf.download('^GSPC', start=start_date, end=end_date, interval=interval)\n",
        "\n",
        "        self.data = dataset\n",
        "        self.nb_samples = nb_samples\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)//self.nb_samples\n",
        "\n",
        "    def __getitem__(self, index) -> Union[torch.Tensor, float]:\n",
        "        # Load one sample more than nb_samples for normalizing, transform\n",
        "        sample = self.data['Close'][index*self.nb_samples:(index+1)*self.nb_samples+1]\n",
        "        # sample = self.data['Close'][index:index+self.nb_samples+1]\n",
        "        sample = torch.tensor(sample)\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)[1:]\n",
        "        else:\n",
        "            sample = sample[1:]\n",
        "        \n",
        "        label = sample[-1] # label is the last elem of sample\n",
        "\n",
        "        sample = sample[:-1] # removes label from sample\n",
        "        return sample, label\n",
        "\n",
        "def normalize_by_last_unknown_price(sample: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Divides the whole stock price sample by the last unknown price w_{p*t-1}\"\"\"\n",
        "    last_price = sample[0] # w_{pt-1}\n",
        "    return sample/last_price\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # download S&P data from yahoo finance\n",
        "    START_DATE = '1950-01-03'\n",
        "    END_DATE = '2021-11-16'\n",
        "    INTERVAL = '1d'\n",
        "    nb_samples = 15\n",
        "\n",
        "    dataset = StockPriceDataset(START_DATE, END_DATE, INTERVAL, nb_samples,\n",
        "                                transform=normalize_by_last_unknown_price)\n",
        "\n",
        "    dataloader = DataLoader(dataset, batch_size=16)\n",
        "    print(len(dataloader))\n",
        "    # for i_batch, batch in enumerate(dataloader):\n",
        "    #     print(\"i_batch = {}, batch = {}\".format(i_batch, batch))\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-PViga_2gvF"
      },
      "source": [
        "## ModÃ¨le"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZyhPYo82poe"
      },
      "source": [
        "from torch.nn import LSTM, Module, Dropout, ModuleList"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8eW8s6T2n-s"
      },
      "source": [
        "class StockAI(Module):\n",
        "     \n",
        "    def __init__(self, input_size, lstm_size, num_layers, keep_prob) -> None:\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.lstm_size = lstm_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm_list = ModuleList([LSTM(self.input_size, self.lstm_size) for _ in range(self.num_layers)])\n",
        "        self.dropout_list = ModuleList([Dropout(1-keep_prob) for _ in range(self.num_layers)])\n",
        "\n",
        "    \n",
        "    def forward(self,x):\n",
        "        y = x\n",
        "        for i in range(self.num_layers):\n",
        "            y = self.lstm_list[i](x)\n",
        "            y = self.dropout_list[i](x)\n",
        "        return y\n",
        "    "
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PERSa2AB2t9V"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl5Xcxyb2wP2"
      },
      "source": [
        "class StockAIConfig():\n",
        "    config = {\n",
        "        \"model\":{\n",
        "            \"input_size\": 1,\n",
        "            \"lstm_size\": 128,\n",
        "            \"num_layers\": 1,\n",
        "            \"keep_prob\": 0.8\n",
        "        },\n",
        "\n",
        "        \"dataset_train\":{\n",
        "            \"start_date\": '1950-01-03',\n",
        "            \"end_date\": '2008-11-16',\n",
        "            \"interval_date\": '1d',\n",
        "            \"nb_samples\":15,\n",
        "            \"batch_size\": 16,\n",
        "            \"shuffle\":False\n",
        "        },\n",
        "        \"dataset_test\":{\n",
        "            \"start_date\": '2008-11-17',\n",
        "            \"end_date\": '2021-11-16',\n",
        "            \"interval_date\": '1d',\n",
        "            \"nb_samples\":15,\n",
        "            \"batch_size\": 16,\n",
        "            \"shuffle\":False\n",
        "        },\n",
        "\n",
        "        \"learning\":{\n",
        "            \"num_steps\": 30,\n",
        "            \"init_lr\": 1e-03,\n",
        "            \"lr_decay\": 0.99,\n",
        "            \"init_epoch\": 5,\n",
        "            \"max_epoch\": 50\n",
        "        }   \n",
        "    }"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhwEsvys21gH"
      },
      "source": [
        "##Prediction : Train / Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLTXAyp320x-"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import RMSprop"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mATSU_bg25Qv",
        "outputId": "9f5cf778-9285-40f7-da86-491511472022"
      },
      "source": [
        "# Model config\n",
        "config = StockAIConfig().config\n",
        "\n",
        "# CUDA for PyTorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Init of the Dataset_train\n",
        "dataset_train = StockPriceDataset(config[\"dataset_train\"][\"start_date\"], \n",
        "                            config[\"dataset_train\"][\"end_date\"],\n",
        "                            config[\"dataset_train\"][\"interval_date\"], \n",
        "                            config[\"dataset_train\"][\"nb_samples\"],\n",
        "                            transform=normalize_by_last_unknown_price)\n",
        "\n",
        "# Init dataloader of the Dataset_train\n",
        "dataloader_train = DataLoader(dataset_train, config[\"dataset_train\"][\"batch_size\"], config[\"dataset_train\"][\"shuffle\"], drop_last=True)\n",
        "\n",
        "# Init of the Dataset_test\n",
        "dataset_test = StockPriceDataset(config[\"dataset_test\"][\"start_date\"], \n",
        "                            config[\"dataset_test\"][\"end_date\"],\n",
        "                            config[\"dataset_test\"][\"interval_date\"], \n",
        "                            config[\"dataset_test\"][\"nb_samples\"],\n",
        "                            transform=normalize_by_last_unknown_price)\n",
        "\n",
        "# Init dataloader of Dataset_test\n",
        "dataloader_test = DataLoader(dataset_test, config[\"dataset_test\"][\"batch_size\"], config[\"dataset_test\"][\"shuffle\"], drop_last=True)\n",
        "\n",
        "# Init of the model\n",
        "model = StockAI(config[\"model\"][\"input_size\"],\n",
        "                config[\"model\"][\"lstm_size\"],\n",
        "                config[\"model\"][\"num_layers\"],\n",
        "                config[\"model\"][\"keep_prob\"])\n",
        "\n",
        "# Learning rate to use along the epochs\n",
        "learning_rates = [config[\"learning\"][\"init_lr\"] * (config[\"learning\"][\"lr_decay\"] ** max(float(i + 1 - config[\"learning\"][\"init_epoch\"]), 0.0)) for i in range(config[\"learning\"][\"max_epoch\"])]\n",
        "\n",
        "# Loss\n",
        "loss_fn = MSELoss()\n",
        "optimizer = RMSprop(model.parameters(), lr=learning_rates[0], eps=1e-08)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzAMljJz7AQt",
        "outputId": "73a09456-2fe1-4b19-87e9-efdb046f94a1"
      },
      "source": [
        "len(dataloader_train)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQt6ZwCR3Ale",
        "outputId": "3cb285e1-8741-4aa0-9ea2-74cb50e5c2cc"
      },
      "source": [
        "# Learning\n",
        "for epoch_step in range(config[\"learning\"][\"max_epoch\"]):\n",
        "    lr = learning_rates[epoch_step]\n",
        "    print(f\"Running for epoch {epoch_step}...\")\n",
        "    for i_batch, batch in enumerate(dataloader_train):\n",
        "        x, y = batch\n",
        "        x = torch.unsqueeze(x, -1).float()\n",
        "        y = y.float()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        y_pred = model.forward(x)\n",
        "        loss = torch.autograd.Variable(loss_fn(y_pred, y), requires_grad=True)\n",
        "\n",
        "        if i_batch%10==0:\n",
        "            print(f\"step: {i_batch}, loss = {loss}\")\n",
        "\n",
        "        # Zero gradients, perform a backward pass, and update the weights.\n",
        "        optimizer.zero_grad()\n",
        "        # loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running for epoch 0...\n",
            "step: 0, loss = 0.23164567351341248\n",
            "step: 10, loss = 0.26553449034690857\n",
            "step: 20, loss = 0.26878464221954346\n",
            "step: 30, loss = 0.2568964660167694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 40, loss = 0.25350311398506165\n",
            "step: 50, loss = 0.2149365395307541\n",
            "step: 60, loss = 0.25484320521354675\n",
            "Running for epoch 1...\n",
            "step: 0, loss = 0.23554246127605438\n",
            "step: 10, loss = 0.2621947228908539\n",
            "step: 20, loss = 0.2974683940410614\n",
            "step: 30, loss = 0.26550665497779846\n",
            "step: 40, loss = 0.23632611334323883\n",
            "step: 50, loss = 0.27096685767173767\n",
            "step: 60, loss = 0.2420056313276291\n",
            "Running for epoch 2...\n",
            "step: 0, loss = 0.2443443387746811\n",
            "step: 10, loss = 0.25730183720588684\n",
            "step: 20, loss = 0.24456095695495605\n",
            "step: 30, loss = 0.277869313955307\n",
            "step: 40, loss = 0.24509792029857635\n",
            "step: 50, loss = 0.26694878935813904\n",
            "step: 60, loss = 0.21770481765270233\n",
            "Running for epoch 3...\n",
            "step: 0, loss = 0.2101908177137375\n",
            "step: 10, loss = 0.22040104866027832\n",
            "step: 20, loss = 0.26846617460250854\n",
            "step: 30, loss = 0.23177795112133026\n",
            "step: 40, loss = 0.29501789808273315\n",
            "step: 50, loss = 0.24020805954933167\n",
            "step: 60, loss = 0.2422550469636917\n",
            "Running for epoch 4...\n",
            "step: 0, loss = 0.25276321172714233\n",
            "step: 10, loss = 0.23680159449577332\n",
            "step: 20, loss = 0.2232203632593155\n",
            "step: 30, loss = 0.22734089195728302\n",
            "step: 40, loss = 0.2489188015460968\n",
            "step: 50, loss = 0.25420060753822327\n",
            "step: 60, loss = 0.2840713858604431\n",
            "Running for epoch 5...\n",
            "step: 0, loss = 0.257005900144577\n",
            "step: 10, loss = 0.274779349565506\n",
            "step: 20, loss = 0.23605585098266602\n",
            "step: 30, loss = 0.21072542667388916\n",
            "step: 40, loss = 0.20688465237617493\n",
            "step: 50, loss = 0.2706138789653778\n",
            "step: 60, loss = 0.22638583183288574\n",
            "Running for epoch 6...\n",
            "step: 0, loss = 0.2959413230419159\n",
            "step: 10, loss = 0.2535586357116699\n",
            "step: 20, loss = 0.24814364314079285\n",
            "step: 30, loss = 0.2403089702129364\n",
            "step: 40, loss = 0.24507375061511993\n",
            "step: 50, loss = 0.26723912358283997\n",
            "step: 60, loss = 0.2797388732433319\n",
            "Running for epoch 7...\n",
            "step: 0, loss = 0.20998801290988922\n",
            "step: 10, loss = 0.24550843238830566\n",
            "step: 20, loss = 0.25288107991218567\n",
            "step: 30, loss = 0.2609476149082184\n",
            "step: 40, loss = 0.28325536847114563\n",
            "step: 50, loss = 0.24928821623325348\n",
            "step: 60, loss = 0.22178184986114502\n",
            "Running for epoch 8...\n",
            "step: 0, loss = 0.29153504967689514\n",
            "step: 10, loss = 0.2577217221260071\n",
            "step: 20, loss = 0.23617735505104065\n",
            "step: 30, loss = 0.26938122510910034\n",
            "step: 40, loss = 0.26145827770233154\n",
            "step: 50, loss = 0.1977984458208084\n",
            "step: 60, loss = 0.22196945548057556\n",
            "Running for epoch 9...\n",
            "step: 0, loss = 0.21018151938915253\n",
            "step: 10, loss = 0.23706288635730743\n",
            "step: 20, loss = 0.2730409502983093\n",
            "step: 30, loss = 0.2821381986141205\n",
            "step: 40, loss = 0.24867960810661316\n",
            "step: 50, loss = 0.2358924001455307\n",
            "step: 60, loss = 0.2424052506685257\n",
            "Running for epoch 10...\n",
            "step: 0, loss = 0.24422600865364075\n",
            "step: 10, loss = 0.2369619607925415\n",
            "step: 20, loss = 0.25265732407569885\n",
            "step: 30, loss = 0.20188169181346893\n",
            "step: 40, loss = 0.2703953683376312\n",
            "step: 50, loss = 0.27141979336738586\n",
            "step: 60, loss = 0.24693621695041656\n",
            "Running for epoch 11...\n",
            "step: 0, loss = 0.2658333480358124\n",
            "step: 10, loss = 0.2368108034133911\n",
            "step: 20, loss = 0.2397880256175995\n",
            "step: 30, loss = 0.25224652886390686\n",
            "step: 40, loss = 0.25762274861335754\n",
            "step: 50, loss = 0.26667457818984985\n",
            "step: 60, loss = 0.2720105051994324\n",
            "Running for epoch 12...\n",
            "step: 0, loss = 0.2533133327960968\n",
            "step: 10, loss = 0.26194652915000916\n",
            "step: 20, loss = 0.2195112556219101\n",
            "step: 30, loss = 0.23551222681999207\n",
            "step: 40, loss = 0.2749386131763458\n",
            "step: 50, loss = 0.23185160756111145\n",
            "step: 60, loss = 0.26414403319358826\n",
            "Running for epoch 13...\n",
            "step: 0, loss = 0.29180625081062317\n",
            "step: 10, loss = 0.24952666461467743\n",
            "step: 20, loss = 0.2981886863708496\n",
            "step: 30, loss = 0.28207892179489136\n",
            "step: 40, loss = 0.26511332392692566\n",
            "step: 50, loss = 0.2623167932033539\n",
            "step: 60, loss = 0.23398372530937195\n",
            "Running for epoch 14...\n",
            "step: 0, loss = 0.23203715682029724\n",
            "step: 10, loss = 0.22493131458759308\n",
            "step: 20, loss = 0.22005043923854828\n",
            "step: 30, loss = 0.2735878527164459\n",
            "step: 40, loss = 0.2699119448661804\n",
            "step: 50, loss = 0.2278604805469513\n",
            "step: 60, loss = 0.25097182393074036\n",
            "Running for epoch 15...\n",
            "step: 0, loss = 0.28316250443458557\n",
            "step: 10, loss = 0.25336170196533203\n",
            "step: 20, loss = 0.26476505398750305\n",
            "step: 30, loss = 0.26524659991264343\n",
            "step: 40, loss = 0.20651786029338837\n",
            "step: 50, loss = 0.23242731392383575\n",
            "step: 60, loss = 0.2802751362323761\n",
            "Running for epoch 16...\n",
            "step: 0, loss = 0.24886398017406464\n",
            "step: 10, loss = 0.24103163182735443\n",
            "step: 20, loss = 0.2186235934495926\n",
            "step: 30, loss = 0.2527407705783844\n",
            "step: 40, loss = 0.295714408159256\n",
            "step: 50, loss = 0.2921511232852936\n",
            "step: 60, loss = 0.27547624707221985\n",
            "Running for epoch 17...\n",
            "step: 0, loss = 0.23963364958763123\n",
            "step: 10, loss = 0.26208558678627014\n",
            "step: 20, loss = 0.23563142120838165\n",
            "step: 30, loss = 0.26962536573410034\n",
            "step: 40, loss = 0.20660623908042908\n",
            "step: 50, loss = 0.24933531880378723\n",
            "step: 60, loss = 0.28345614671707153\n",
            "Running for epoch 18...\n",
            "step: 0, loss = 0.3089302182197571\n",
            "step: 10, loss = 0.27086085081100464\n",
            "step: 20, loss = 0.23148226737976074\n",
            "step: 30, loss = 0.24833610653877258\n",
            "step: 40, loss = 0.2573235034942627\n",
            "step: 50, loss = 0.2450568825006485\n",
            "step: 60, loss = 0.2966384291648865\n",
            "Running for epoch 19...\n",
            "step: 0, loss = 0.2226317822933197\n",
            "step: 10, loss = 0.23308290541172028\n",
            "step: 20, loss = 0.21540823578834534\n",
            "step: 30, loss = 0.25240224599838257\n",
            "step: 40, loss = 0.2527202069759369\n",
            "step: 50, loss = 0.2665797770023346\n",
            "step: 60, loss = 0.2514505386352539\n",
            "Running for epoch 20...\n",
            "step: 0, loss = 0.24080093204975128\n",
            "step: 10, loss = 0.21633325517177582\n",
            "step: 20, loss = 0.2856905162334442\n",
            "step: 30, loss = 0.2531168758869171\n",
            "step: 40, loss = 0.2534261643886566\n",
            "step: 50, loss = 0.2402983009815216\n",
            "step: 60, loss = 0.205673485994339\n",
            "Running for epoch 21...\n",
            "step: 0, loss = 0.19730670750141144\n",
            "step: 10, loss = 0.3248412013053894\n",
            "step: 20, loss = 0.21503743529319763\n",
            "step: 30, loss = 0.23973219096660614\n",
            "step: 40, loss = 0.25746408104896545\n",
            "step: 50, loss = 0.2879161834716797\n",
            "step: 60, loss = 0.3043525218963623\n",
            "Running for epoch 22...\n",
            "step: 0, loss = 0.24396254122257233\n",
            "step: 10, loss = 0.2578378915786743\n",
            "step: 20, loss = 0.24358323216438293\n",
            "step: 30, loss = 0.23183584213256836\n",
            "step: 40, loss = 0.2574508786201477\n",
            "step: 50, loss = 0.23710419237613678\n",
            "step: 60, loss = 0.2174806296825409\n",
            "Running for epoch 23...\n",
            "step: 0, loss = 0.2532236576080322\n",
            "step: 10, loss = 0.22448347508907318\n",
            "step: 20, loss = 0.2487080842256546\n",
            "step: 30, loss = 0.2233077585697174\n",
            "step: 40, loss = 0.26958879828453064\n",
            "step: 50, loss = 0.2669219374656677\n",
            "step: 60, loss = 0.21748904883861542\n",
            "Running for epoch 24...\n",
            "step: 0, loss = 0.26556476950645447\n",
            "step: 10, loss = 0.2665635943412781\n",
            "step: 20, loss = 0.18188418447971344\n",
            "step: 30, loss = 0.2398056983947754\n",
            "step: 40, loss = 0.2744343876838684\n",
            "step: 50, loss = 0.23716960847377777\n",
            "step: 60, loss = 0.24290265142917633\n",
            "Running for epoch 25...\n",
            "step: 0, loss = 0.24798181653022766\n",
            "step: 10, loss = 0.27473416924476624\n",
            "step: 20, loss = 0.2855863571166992\n",
            "step: 30, loss = 0.22783204913139343\n",
            "step: 40, loss = 0.24498488008975983\n",
            "step: 50, loss = 0.27890744805336\n",
            "step: 60, loss = 0.23833496868610382\n",
            "Running for epoch 26...\n",
            "step: 0, loss = 0.2950877249240875\n",
            "step: 10, loss = 0.24908597767353058\n",
            "step: 20, loss = 0.2927326560020447\n",
            "step: 30, loss = 0.26109790802001953\n",
            "step: 40, loss = 0.244810551404953\n",
            "step: 50, loss = 0.24957621097564697\n",
            "step: 60, loss = 0.2507140040397644\n",
            "Running for epoch 27...\n",
            "step: 0, loss = 0.22729650139808655\n",
            "step: 10, loss = 0.20349757373332977\n",
            "step: 20, loss = 0.27724674344062805\n",
            "step: 30, loss = 0.24810561537742615\n",
            "step: 40, loss = 0.25722143054008484\n",
            "step: 50, loss = 0.26201504468917847\n",
            "step: 60, loss = 0.2670201063156128\n",
            "Running for epoch 28...\n",
            "step: 0, loss = 0.26580125093460083\n",
            "step: 10, loss = 0.2785514295101166\n",
            "step: 20, loss = 0.2606600821018219\n",
            "step: 30, loss = 0.2532433569431305\n",
            "step: 40, loss = 0.24081848561763763\n",
            "step: 50, loss = 0.2841785252094269\n",
            "step: 60, loss = 0.21757571399211884\n",
            "Running for epoch 29...\n",
            "step: 0, loss = 0.24436883628368378\n",
            "step: 10, loss = 0.2829723656177521\n",
            "step: 20, loss = 0.23559336364269257\n",
            "step: 30, loss = 0.26571765542030334\n",
            "step: 40, loss = 0.2536337971687317\n",
            "step: 50, loss = 0.23186860978603363\n",
            "step: 60, loss = 0.2378617376089096\n",
            "Running for epoch 30...\n",
            "step: 0, loss = 0.22364139556884766\n",
            "step: 10, loss = 0.23664431273937225\n",
            "step: 20, loss = 0.2231709212064743\n",
            "step: 30, loss = 0.22329463064670563\n",
            "step: 40, loss = 0.2704246938228607\n",
            "step: 50, loss = 0.2410428375005722\n",
            "step: 60, loss = 0.28358200192451477\n",
            "Running for epoch 31...\n",
            "step: 0, loss = 0.2576129138469696\n",
            "step: 10, loss = 0.2541521489620209\n",
            "step: 20, loss = 0.28600040078163147\n",
            "step: 30, loss = 0.2739700973033905\n",
            "step: 40, loss = 0.252786248922348\n",
            "step: 50, loss = 0.24138715863227844\n",
            "step: 60, loss = 0.2752537727355957\n",
            "Running for epoch 32...\n",
            "step: 0, loss = 0.23167875409126282\n",
            "step: 10, loss = 0.22436508536338806\n",
            "step: 20, loss = 0.24448810517787933\n",
            "step: 30, loss = 0.2445773184299469\n",
            "step: 40, loss = 0.2409386932849884\n",
            "step: 50, loss = 0.3147377371788025\n",
            "step: 60, loss = 0.2590097188949585\n",
            "Running for epoch 33...\n",
            "step: 0, loss = 0.3174353241920471\n",
            "step: 10, loss = 0.24555864930152893\n",
            "step: 20, loss = 0.2896578013896942\n",
            "step: 30, loss = 0.2616642117500305\n",
            "step: 40, loss = 0.21115198731422424\n",
            "step: 50, loss = 0.2322072982788086\n",
            "step: 60, loss = 0.26351454854011536\n",
            "Running for epoch 34...\n",
            "step: 0, loss = 0.2278471738100052\n",
            "step: 10, loss = 0.25353050231933594\n",
            "step: 20, loss = 0.2154613584280014\n",
            "step: 30, loss = 0.2522028982639313\n",
            "step: 40, loss = 0.2573496997356415\n",
            "step: 50, loss = 0.27097564935684204\n",
            "step: 60, loss = 0.2725750803947449\n",
            "Running for epoch 35...\n",
            "step: 0, loss = 0.24052388966083527\n",
            "step: 10, loss = 0.23717038333415985\n",
            "step: 20, loss = 0.24454006552696228\n",
            "step: 30, loss = 0.2522755563259125\n",
            "step: 40, loss = 0.2877676784992218\n",
            "step: 50, loss = 0.25377780199050903\n",
            "step: 60, loss = 0.2631813585758209\n",
            "Running for epoch 36...\n",
            "step: 0, loss = 0.28761038184165955\n",
            "step: 10, loss = 0.25378191471099854\n",
            "step: 20, loss = 0.28946805000305176\n",
            "step: 30, loss = 0.185686856508255\n",
            "step: 40, loss = 0.2529500722885132\n",
            "step: 50, loss = 0.24543936550617218\n",
            "step: 60, loss = 0.24220958352088928\n",
            "Running for epoch 37...\n",
            "step: 0, loss = 0.33486929535865784\n",
            "step: 10, loss = 0.2582415044307709\n",
            "step: 20, loss = 0.22762446105480194\n",
            "step: 30, loss = 0.25726252794265747\n",
            "step: 40, loss = 0.25822514295578003\n",
            "step: 50, loss = 0.2417490929365158\n",
            "step: 60, loss = 0.25126543641090393\n",
            "Running for epoch 38...\n",
            "step: 0, loss = 0.23628316819667816\n",
            "step: 10, loss = 0.23674948513507843\n",
            "step: 20, loss = 0.22742190957069397\n",
            "step: 30, loss = 0.22783328592777252\n",
            "step: 40, loss = 0.19812242686748505\n",
            "step: 50, loss = 0.25797632336616516\n",
            "step: 60, loss = 0.2591004967689514\n",
            "Running for epoch 39...\n",
            "step: 0, loss = 0.2958950102329254\n",
            "step: 10, loss = 0.21202750504016876\n",
            "step: 20, loss = 0.2685674726963043\n",
            "step: 30, loss = 0.21071355044841766\n",
            "step: 40, loss = 0.27025532722473145\n",
            "step: 50, loss = 0.19768548011779785\n",
            "step: 60, loss = 0.2588723599910736\n",
            "Running for epoch 40...\n",
            "step: 0, loss = 0.27008265256881714\n",
            "step: 10, loss = 0.21230581402778625\n",
            "step: 20, loss = 0.26101192831993103\n",
            "step: 30, loss = 0.22299937903881073\n",
            "step: 40, loss = 0.23578870296478271\n",
            "step: 50, loss = 0.25311505794525146\n",
            "step: 60, loss = 0.2632804811000824\n",
            "Running for epoch 41...\n",
            "step: 0, loss = 0.24089765548706055\n",
            "step: 10, loss = 0.220429927110672\n",
            "step: 20, loss = 0.27706846594810486\n",
            "step: 30, loss = 0.2612646222114563\n",
            "step: 40, loss = 0.24444524943828583\n",
            "step: 50, loss = 0.28321537375450134\n",
            "step: 60, loss = 0.23504285514354706\n",
            "Running for epoch 42...\n",
            "step: 0, loss = 0.23666389286518097\n",
            "step: 10, loss = 0.17840741574764252\n",
            "step: 20, loss = 0.2976723313331604\n",
            "step: 30, loss = 0.29129335284233093\n",
            "step: 40, loss = 0.26171496510505676\n",
            "step: 50, loss = 0.28407952189445496\n",
            "step: 60, loss = 0.2459544688463211\n",
            "Running for epoch 43...\n",
            "step: 0, loss = 0.24453602731227875\n",
            "step: 10, loss = 0.2454320192337036\n",
            "step: 20, loss = 0.21910293400287628\n",
            "step: 30, loss = 0.2616270184516907\n",
            "step: 40, loss = 0.25755825638771057\n",
            "step: 50, loss = 0.2495017796754837\n",
            "step: 60, loss = 0.22578445076942444\n",
            "Running for epoch 44...\n",
            "step: 0, loss = 0.2227480560541153\n",
            "step: 10, loss = 0.2287687212228775\n",
            "step: 20, loss = 0.2566274106502533\n",
            "step: 30, loss = 0.2864202857017517\n",
            "step: 40, loss = 0.25327882170677185\n",
            "step: 50, loss = 0.23691630363464355\n",
            "step: 60, loss = 0.21790149807929993\n",
            "Running for epoch 45...\n",
            "step: 0, loss = 0.29222461581230164\n",
            "step: 10, loss = 0.22861364483833313\n",
            "step: 20, loss = 0.24113835394382477\n",
            "step: 30, loss = 0.2404274195432663\n",
            "step: 40, loss = 0.24947072565555573\n",
            "step: 50, loss = 0.28425589203834534\n",
            "step: 60, loss = 0.27161166071891785\n",
            "Running for epoch 46...\n",
            "step: 0, loss = 0.24102313816547394\n",
            "step: 10, loss = 0.2579514980316162\n",
            "step: 20, loss = 0.24818065762519836\n",
            "step: 30, loss = 0.2530682384967804\n",
            "step: 40, loss = 0.2616419792175293\n",
            "step: 50, loss = 0.27448683977127075\n",
            "step: 60, loss = 0.27180710434913635\n",
            "Running for epoch 47...\n",
            "step: 0, loss = 0.23572304844856262\n",
            "step: 10, loss = 0.21234823763370514\n",
            "step: 20, loss = 0.24786952137947083\n",
            "step: 30, loss = 0.2310582846403122\n",
            "step: 40, loss = 0.2278929203748703\n",
            "step: 50, loss = 0.26237472891807556\n",
            "step: 60, loss = 0.30020782351493835\n",
            "Running for epoch 48...\n",
            "step: 0, loss = 0.27453896403312683\n",
            "step: 10, loss = 0.25787776708602905\n",
            "step: 20, loss = 0.24453666806221008\n",
            "step: 30, loss = 0.25320520997047424\n",
            "step: 40, loss = 0.22740136086940765\n",
            "step: 50, loss = 0.2490633875131607\n",
            "step: 60, loss = 0.2797778844833374\n",
            "Running for epoch 49...\n",
            "step: 0, loss = 0.28265395760536194\n",
            "step: 10, loss = 0.233077272772789\n",
            "step: 20, loss = 0.2811827063560486\n",
            "step: 30, loss = 0.25681576132774353\n",
            "step: 40, loss = 0.2240220457315445\n",
            "step: 50, loss = 0.2330847531557083\n",
            "step: 60, loss = 0.22222836315631866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2naoTex3DFi",
        "outputId": "2dbf174c-1784-487e-87a2-28879e5e5e05"
      },
      "source": [
        "#test\n",
        "runnning_mape = 0\n",
        "for i_batch, batch in enumerate(dataloader_test):\n",
        "        x, y = batch\n",
        "        x = torch.unsqueeze(x, -1).float()\n",
        "        y = y.float()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        y_pred = model.forward(x)\n",
        "        error = torch.mean(torch.abs((y - y_pred) / y))\n",
        "        runnning_mape += error\n",
        "\n",
        "mape = runnning_mape / len(dataloader_test)\n",
        "print(\"\",mape)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " tensor(0.4035)\n"
          ]
        }
      ]
    }
  ]
}